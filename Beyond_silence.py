import streamlit as st
import tempfile
import torch
import whisper
from transformers import pipeline
import pandas as pd

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
whisper_model = whisper.load_model("base")  # Ø£Ùˆ small/medium Ø­Ø³Ø¨ Ù…Ø§ ØªØ­Ø¨ÙŠ
classifier = pipeline(
    "text-classification", 
    model="path/to/your/fine_tuned_model",  # â† Ø¹Ø¯Ù‘Ù„ÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ù‡Ù†Ø§
    return_all_scores=False
)

st.set_page_config(page_title="Beyond Silence App", page_icon="ğŸ”Š")
st.title("ğŸ”Š Beyond Silence App")
st.info("Transcribes speech to text and detects emotion.")

# Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„ØµÙˆØª
uploaded_file = st.file_uploader("Upload an audio file", type=["wav", "mp3", "m4a"])

if uploaded_file is not None:
    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù…Ø¤Ù‚ØªÙ‹Ø§
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_path = tmp_file.name

    # ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª
    st.audio(uploaded_file, format='audio/wav')

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ù„Ù†Øµ
    st.write("Processing transcription...")
    result = whisper_model.transcribe(tmp_path)
    transcription = result["text"]

    st.subheader("ğŸ“ Transcription:")
    st.write(transcription)

    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
    st.write("Detecting emotion...")
    emotion_result = classifier(transcription)[0]
    emotion_label = emotion_result['label']
    emotion_score = emotion_result['score']

    st.subheader("ğŸ˜Š Detected Emotion:")
    st.write(f"{emotion_label} (confidence: {emotion_score:.2f})")

    st.success("Done âœ…")
